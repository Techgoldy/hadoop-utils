#!/opt/ruby/1.9.3/bin/ruby
###
require 'rubygems'
require 'trollop'
require 'houdah'
require 'digest/md5'
require 'base64'

# find out the duplicate hive jobs in the hadoop cluster
# given the hive query string in the job config

# connect to the jobtracker
jclient = Houdah::Client.new 'jobtracker.mydomain.net'

# prep the hash structure
$jobs_info = Hash.new { |h, k| h[k] = {} }
$hive_jobs = Hash.new { |h, k| h[k] = [] }

# iterate through only hive jobs on the jobtracker and
# store the query string and md5sum for later massage
jclient.jobs.each { |job|
  # is it a hive job?
  if ! job.config['hive.query.string'].nil?
    jid = job.jobID.asString.to_s.strip
    $jobs_info[jid]['query_string'] = job.config['hive.query.string'].strip
    $jobs_info[jid]['query_md5'] = Digest::MD5.hexdigest($jobs_info[jid]['query_string'].to_s)
    $hive_jobs[$jobs_info[jid]['query_md5']].push(jid)
  end
}

# parse through the jobs_info collected and find the duplicate jobs
$hive_jobs.select { |k,v| v.length > 1 }.each { |hive_qry, jobs|
  puts "#{hive_qry.to_s} :  #{jobs.to_s}"
}
